{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Natural Language Processing Lab (CODE): CC AI Ep 8","provenance":[{"file_id":"1f8ik5kSPEvDCcM7R_-Wb3AjifizVEsHD","timestamp":1589025177412},{"file_id":"1Z-9lbx7r4dSXUHXsP57KOXHbchItK_HB","timestamp":1564157290958}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"qF_ESTSJT9IX","colab_type":"text"},"source":["## Step 1: Data Analysis and Preparation"]},{"cell_type":"markdown","metadata":{"id":"87ff6wDmJUeN","colab_type":"text"},"source":["Natural language processing is teaching an AI system to understand and produce language, by asking it to find and copy patterns in human behavior. NLP is a huge part of artificial intelligence. \n","\n","To build a natural language processing AI, we need to do four main things: 1) gather and clean the data, 2) set up the model, 3) train the model, and 4) make inferences.\n","\n","First, we need to import our John Green transcripts from Vlogbrothers videos."]},{"cell_type":"code","metadata":{"id":"-bxV3YjC7psj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"outputId":"fe1dc887-37c2-4907-ea88-0700329df25f","executionInfo":{"status":"ok","timestamp":1589037146464,"user_tz":-180,"elapsed":2262,"user":{"displayName":"Turhan Can Kargın","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_nBTtpJH69xacdXtHC85zJwK_OgZQ-lAUwUqgYqo=s64","userId":"17271240165502760084"}}},"source":["# STEP 1.1\n","\n","from urllib.request import urlopen\n","txt = urlopen(\"https://raw.githubusercontent.com/crash-course-ai/lab2-nlp/master/vlogbrothers.txt\").read().decode('ascii').split(\"\\n\")\n","print(\"Our dataset contains {} vlogbrothers scripts\".format(len(txt)))\n","# ADVANCED_CHANGEME -- You can change this to load any text file \n","# You want it to be one line of plain text for every script.  Extra\n","# annotations like [John:] or *starts coughing* make learning more difficult.\n","everything = set([w for s in txt for w in s.split()])\n","print(\"and {} lexical types\".format(len(everything)))"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Our dataset contains 626 vlogbrothers scripts\n","and 31924 lexical types\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sc3u5U44A8ap","colab_type":"text"},"source":["Next, we need to do some preprocessing on our data to prepare it for our model. We're going to tokenize our text and split every sentence into a list of lexical tokens, including some rules for puctuation. And we're going to add markers for the start and end of each segment.\n","\n","We also want to divide all our data into training and validation datasets, so our model can learn from the training data, but we can test it on the validation dataset that it has never seen before. \n"]},{"cell_type":"code","metadata":{"id":"_6RgRCeEATzo","colab_type":"code","colab":{}},"source":["# STEP 1.2\n","\n","# 1. Import the tokenizer\n","import spacy\n","nlp = spacy.load(\"en\", disable=[\"parser\",\"tagger\",\"ner\",\"textcat\"])\n","\n","# 2. Tokenize\n","txt = [nlp(s) for s in txt]\n","\n","# 3. Mark the beginning and end of each script \n","txt = [ [\"<s>\"] + [str(w) for w in s] + [\"</s>\"] for s in txt]\n","\n","# 4. Separate the data into training and validation\n","train = txt[:-5]\n","valid = txt[-5:]\n","\n","# 5. Flatten the lists into one long string and remove extra whitespace\n","train = [w for s in train for w in s if not w.isspace()]\n","valid = [w for s in valid for w in s if not w.isspace()]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GiFC8YqoC5jQ","colab_type":"text"},"source":["Great!  Now let's take a look at our data statistics -- specifically, how many lexical types and how many lexical tokens we have."]},{"cell_type":"code","metadata":{"id":"JzYMScnsDQ2V","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"outputId":"c0d69973-2f9b-4c3a-820d-82f91cea7178","executionInfo":{"status":"ok","timestamp":1589037181451,"user_tz":-180,"elapsed":1457,"user":{"displayName":"Turhan Can Kargın","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_nBTtpJH69xacdXtHC85zJwK_OgZQ-lAUwUqgYqo=s64","userId":"17271240165502760084"}}},"source":["# STEP 1.3\n","\n","\"\"\"\n","    How big is our dataset?\n","\"\"\"\n","print(\"Our training dataset contains {} lexical types\".format(len(set(train))))\n","print(\"Our training dataset contains {} lexical tokens\".format(len(train)))"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Our training dataset contains 22939 lexical types\n","Our training dataset contains 569574 lexical tokens\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"09KAnNLIOaeE","colab_type":"text"},"source":["Let's take a closer look at the vocabulary and see what kinds of words human John Green likes to use more often than others. We’re going to figure out how many lexical types occur more than once, twice, and so on.\n"]},{"cell_type":"code","metadata":{"id":"avE76fKTOdDC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":388},"outputId":"58ca2e0f-93ca-4db7-a815-fb771b9ecbac","executionInfo":{"status":"ok","timestamp":1589037187431,"user_tz":-180,"elapsed":2598,"user":{"displayName":"Turhan Can Kargın","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_nBTtpJH69xacdXtHC85zJwK_OgZQ-lAUwUqgYqo=s64","userId":"17271240165502760084"}}},"source":["# STEP 1.4\n","\n","# 1. Count the frequencies of every word\n","from collections import Counter, defaultdict\n","counts = Counter(train)\n","\n","frequencies = [0]*8\n","for w in counts:\n","  if counts[w] >= 128:\n","    frequencies[0] += 1\n","  elif counts[w] >= 64:\n","    frequencies[1] += 1\n","  elif counts[w] >= 32:\n","    frequencies[2] += 1\n","  elif counts[w] >= 16:\n","    frequencies[3] += 1\n","  elif counts[w] >= 8:\n","    frequencies[4] += 1\n","  elif counts[w] >= 4:\n","    frequencies[5] += 1\n","  elif counts[w] >= 2:\n","    frequencies[6] += 1\n","  else:\n","    frequencies[7] += 1\n","\n","\n","# 2. Plot their distributions\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","f,a = plt.subplots(1,1,figsize=(10,5))\n","a.set(xlabel='Lexical types occuring more then n times', \n","      ylabel='Number of lexical types')\n","\n","labels = [128, 64, 32, 16, 8, 4, 2, 1]\n","_ = sns.barplot(labels, frequencies, ax=a, order=labels)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"],"name":"stderr"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 720x360 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"Hq2wDniV_sEo","colab_type":"text"},"source":["We have a lot of very rare words, words that only occur a single time in the dataset. These are very difficult to use when building a NLP model because our model will try to find and copy patterns, so it needs plenty of examples of how to use each word during training. Let's look at some of these rare words.\n"]},{"cell_type":"code","metadata":{"id":"dHsXx2Kj_0AX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":437},"outputId":"87cb75eb-4463-4639-ca3b-01b11cbe7031","executionInfo":{"status":"ok","timestamp":1589037195991,"user_tz":-180,"elapsed":2256,"user":{"displayName":"Turhan Can Kargın","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_nBTtpJH69xacdXtHC85zJwK_OgZQ-lAUwUqgYqo=s64","userId":"17271240165502760084"}}},"source":["# STEP 1.5\n","\n","from textwrap import wrap\n","rare = [w for w in counts if counts[w] == 1]\n","for line in wrap(\"   \".join([\"{:15s}\".format(w) for w in rare[:100]]), width=70):\n","  print(line)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Pisgah            recycle           Inconvenient      sorta\n","ignored           Sheets            Toilet            Situation\n","oghomamamam       Oomph             Drinking          grizzly\n","malt              minty             alcoholy          tast-\n","achoo             Babysitter        Brave             Eden\n","Biblical          exalted           Eggers            Gourevitch\n","Thur-             patriarchal       Caravans          BP\n","58                Sixteen           condense          12:15\n","Misprinted        floss             terse             Punishment\n","Continuum         Apocalypticism    Emmitt            styrofoam\n","locations         Dances            Boxing            Federation\n","Upper             Poops             Poop              Kirsten\n","Dunst             Umbros            UEFA              Gunter\n","nonfictionaly     nonfictional      Roker             Ilyich\n","Linden            bullshit          Monty             Python\n","Idle              Lilliputians      Naked             gaping\n","theorem           origami           ambiguously       exhaustible\n","grace             Mortal            Kombat            tuba\n","Fighter           Quarterback       jab               Who'd\n","Tiki              Barber            hm                Blaise\n","Pascal            Immanuel          Kant              Mahatma\n","Mandela           Beatles           calculators       trombones\n","D&D               drones            asstica           Ash\n","Lent              hmmm              hmmmmmm           Horrible\n","Himalayas         Huge              Hairy             Terrifying\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OXjNAjt6QElF","colab_type":"text"},"source":["Some of these seem too difficult for our model to learn, like Liliputians. But the model could learn some of these if we helped simplify the words.\n","\n","For example, what if we got rid of numbers by replacing them with #s? And what if we use our knowledge of word morphology to remove some endings like -ed or -ing?"]},{"cell_type":"code","metadata":{"id":"6H0t1qQ0AQhI","colab_type":"code","colab":{}},"source":["# STEP 1.6\n","\n","# This is a little function to help us clean up the data\n","# CHANGEME -- Introduce or remove rules\n","import re\n","def simplify(w):\n","    # Remove extra punctuation\n","    w = w.replace(\"-\", \"\").replace(\"~\",\"\")\n","    \n","    # Replace numbers with # sign\n","    w = re.sub('\\d', '#', w)\n","    \n","    # Change some endings\n","    if len(w) > 3 and w[-2:] in set([\"ed\", \"er\",\"ly\"]):\n","        return [w[:-2], w[-2:]]\n","    elif len(w) > 4 and w[-3:] in set([\"ing\",\"'re\"]):\n","        return [w[:-3], w[-3:]]\n","    return [w]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gp6CiTzOQnua","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":368},"outputId":"3dc37d5c-8645-41f2-f3ea-8480aa38f28b","executionInfo":{"status":"ok","timestamp":1589037233081,"user_tz":-180,"elapsed":1914,"user":{"displayName":"Turhan Can Kargın","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_nBTtpJH69xacdXtHC85zJwK_OgZQ-lAUwUqgYqo=s64","userId":"17271240165502760084"}}},"source":["# STEP 1.7\n","\n","# 1. Go through and clean all of our data\n","train_clean = []\n","for w in train:\n","    for piece in simplify(w):\n","        train_clean.append(piece)\n","valid_clean = []\n","for w in valid:\n","    for piece in simplify(w):\n","        valid_clean.append(piece)\n","        \n","\"\"\"\n","    How big is our dataset?\n","\"\"\"\n","print(\"{} lexical types\".format(len(set(train_clean))))\n","print(\"{} lexical tokens\".format(len(train_clean)))\n","\n","\"\"\"\n","    What's our distribution look like?\n","\"\"\"\n","counts = Counter(train_clean)\n","\n","\n","frequencies = [0]*8\n","for w in counts:\n","  if counts[w] >= 128:\n","    frequencies[0] += 1\n","  elif counts[w] >= 64:\n","    frequencies[1] += 1\n","  elif counts[w] >= 32:\n","    frequencies[2] += 1\n","  elif counts[w] >= 16:\n","    frequencies[3] += 1\n","  elif counts[w] >= 8:\n","    frequencies[4] += 1\n","  elif counts[w] >= 4:\n","    frequencies[5] += 1\n","  elif counts[w] >= 2:\n","    frequencies[6] += 1\n","  else:\n","    frequencies[7] += 1\n","\n","\n","# 2. Plot their distributions\n","f,a = plt.subplots(1,1,figsize=(10,5))\n","a.set(xlabel='Lexical types occuring more then n times', \n","      ylabel='Number of lexical types')\n","\n","labels = [128, 64, 32, 16, 8, 4, 2, 1]\n","_ = sns.barplot(labels, frequencies, ax=a, order=labels)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["19982 lexical types\n","612547 lexical tokens\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 720x360 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"7kQ1O3NbRL0M","colab_type":"text"},"source":["This looks a lot better, because the bar of rare words that occur only once is smaller. There's probably more we can do, but let's keep moving forward.\n","\n","There will /always/ be rare words, and the model needs to know how to handle these one way or another. So, we're going to replace rare lexical types with an `unk`, indicating they are unknown. This will let our model keep writing when it bumps into a one-time made-up word like \"zombicorns.\""]},{"cell_type":"code","metadata":{"id":"QKCex8fuRoLR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":334},"outputId":"9db3f7fd-70d3-4a72-fcb6-b9a7a240351b","executionInfo":{"status":"ok","timestamp":1589037243195,"user_tz":-180,"elapsed":1087,"user":{"displayName":"Turhan Can Kargın","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_nBTtpJH69xacdXtHC85zJwK_OgZQ-lAUwUqgYqo=s64","userId":"17271240165502760084"}}},"source":["# STEP 1.8\n","\n","counts_clean = Counter(train_clean)\n","train_unk = [w if counts_clean[w] > 1 else \"unk\" for w in train_clean]\n","valid_unk = [w if w in counts_clean and counts_clean[w] > 1 \\\n","               else \"unk\" for w in valid_clean]\n","\n","# Let's plot these one last time\n","counts = Counter(train_unk)\n","\n","frequencies = [0]*8\n","for w in counts:\n","  if counts[w] >= 128:\n","    frequencies[0] += 1\n","  elif counts[w] >= 64:\n","    frequencies[1] += 1\n","  elif counts[w] >= 32:\n","    frequencies[2] += 1\n","  elif counts[w] >= 16:\n","    frequencies[3] += 1\n","  elif counts[w] >= 8:\n","    frequencies[4] += 1\n","  elif counts[w] >= 4:\n","    frequencies[5] += 1\n","  elif counts[w] >= 2:\n","    frequencies[6] += 1\n","  else:\n","    frequencies[7] += 1\n","\n","\n","# 2. Plot their distributions\n","f,a = plt.subplots(1,1,figsize=(10,5))\n","a.set(xlabel='Lexical types occuring more then n times', \n","      ylabel='Number of lexical types')\n","\n","labels = [128, 64, 32, 16, 8, 4, 2, 1]\n","_ = sns.barplot(labels, frequencies, ax=a, order=labels)"],"execution_count":9,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 720x360 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"U4jvogjOSkxZ","colab_type":"text"},"source":["Great! Now we've really cut down on our rare words. Let's take a look at what we're losing."]},{"cell_type":"code","metadata":{"id":"vPcAiPeRAW8k","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":470},"outputId":"92567a57-0c52-41a2-c3a2-230f85d6380d","executionInfo":{"status":"ok","timestamp":1589037248797,"user_tz":-180,"elapsed":710,"user":{"displayName":"Turhan Can Kargın","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_nBTtpJH69xacdXtHC85zJwK_OgZQ-lAUwUqgYqo=s64","userId":"17271240165502760084"}}},"source":["# STEP 1.9\n","\n","rare = [w for w in counts_clean if counts_clean[w] == 1]\n","rare.sort()\n","for line in wrap(\"   \".join([\"{:15s}\".format(w) for w in rare[-100:]]), width=70):\n","  print(line)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["wheels            wheezywait        whereabouts       whereby\n","whilst            whim              whimp             whimper\n","whines            whippersnappers   whiskeys          whistle\n","whittl            wholesale         whoo              whoosey\n","whopp             wi                widest            widows\n","wields            wifi              wigg              wil\n","wildebeests       wilderness        wildflowers\n","willallpreordersofthefaultinourstarsbesign\n","willallpreordersofturtlesallthewaydownbesign   willful\n","willingness       willpow           wimp              wina\n","windowless        winds             winkel            winter\n","wipe              wipes             wires             wis\n","witch             withdrew          witnesses         witty\n","woahWOAHWOAH      wobb              wobby             womb\n","woodblock         woodcuts          woodpeck          wooooo\n","wordless          workedOn          workings          worldliness\n","wormhole          worms             worsens           worthwhile\n","wounds            wowzy             wrap              wrest\n","wriggl            wrist             wrought           wwwaaaahhhh\n","wynflete          xenophobic        y'just            ya'know\n","yacht             yappy             yawn              yeaahhh\n","yearbook          yeeedadababoobok   yen               yo\n","yoga              yop               youMaybe          youngest\n","youngst           yousendit         yummy             zany\n","zapp              zeal              zer               zeros\n","zombicorns        zombieness        zombification     zoos\n","zrbajarb          zu\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TXtWN3snTWpy","colab_type":"text"},"source":["`woahWOAHWOAH`, `wowzy`, `zrbajarb` ... we'll be fine without those words for today. So now we have our data, we're done with preprocessing, and we're ready to build a model!"]},{"cell_type":"markdown","metadata":{"id":"r7ttbZ-mUIed","colab_type":"text"},"source":["## Step 2: Model Definitions"]},{"cell_type":"markdown","metadata":{"id":"ZAEt8AhuvNyt","colab_type":"text"},"source":["There are a couple key things that we need to do to build a model. First, we need to convert the sentences into lists or arrays of numbers. We want one word for every lexical type, so we’ll build a dictionary that assigns every word in our vocabulary a number."]},{"cell_type":"code","metadata":{"id":"ZIcK-thVBcNW","colab_type":"code","colab":{}},"source":["# STEP 2.1\n","\n","\"\"\"\n","  Prepare our datasets by converting words to numbers\n","\"\"\"\n","# Create a mapping from words <-> numbers\n","vocabulary = set(train_unk)\n","word_to_num = {}\n","num_to_word = {}\n","for num, word in enumerate(vocabulary):\n","  word_to_num[word] = num\n","  num_to_word[num] = word\n","\n","# Convert our datasets into numbers\n","import torch\n","train = torch.LongTensor(len(train_unk))\n","for i in range(len(train_unk)):\n","  train[i] = word_to_num[train_unk[i]]\n","\n","valid = torch.LongTensor(len(valid_unk))\n","for i in range(len(valid_unk)):\n","  valid[i] = word_to_num[valid_unk[i]]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z3mVbMMVV73q","colab_type":"text"},"source":["Next, we need to convert our dataset into bite-sized pieces for the model.  Specifically, the `batch_size` is how many examples we look at during each step of training and the `seq_len` is how many words the model sees per example.  Here are some helpful functions that will do that for us."]},{"cell_type":"code","metadata":{"id":"FetTV331Vqsq","colab_type":"code","colab":{}},"source":["# STEP 2.2\n","\n","# Parameters\n","batch_size = 20   \n","seq_len = 35        # CHANGEME\n","\n","# Tell Torch to use a GPU for computation\n","device = torch.device(\"cuda\")\n","# Setting the random seed decreases variability\n","# Remove next three lines if running on your laptop\n","torch.manual_seed(0)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","\n","# citation: https://github.com/pytorch/examples/tree/master/word_language_model\n","def batchify(data, bsz):\n","    # Work out how cleanly we can divide the dataset into bsz parts.\n","    nbatch = data.size(0) // bsz\n","    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n","    data = data.narrow(0, 0, nbatch * bsz)\n","    # Evenly divide the data across the bsz batches.\n","    data = data.view(bsz, -1).t().contiguous()\n","    return data.to(device)\n","\n","def get_batch(source, i, seq_len):\n","    seq_len = min(seq_len, len(source) - 1 - i)\n","    data = source[i:i+seq_len]\n","    target = source[i+1:i+1+seq_len].view(-1)\n","    return data, target\n","\n","def repackage_hidden(h):\n","    \"\"\"Wraps hidden states in new Tensors, to detach them from their history.\"\"\"\n","    if isinstance(h, torch.Tensor):\n","        return h.detach()\n","    else:\n","        return tuple(repackage_hidden(v) for v in h)\n","\n","train = batchify(train, batch_size)\n","valid = batchify(valid, batch_size)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aj6OxhsOWs13","colab_type":"text"},"source":["Now, let's actually build our AI! We’ll need two key parts, an embedding matrix and a recurrent neural network or RNN.\n","\n","An embedding matrix is a big list of vectors (which is basically a big table of numbers) where each row corresponds to a different word. These vector-rows capture how related two words are -- if two words are used in similar ways, then the numbers in their vectors should be similar. To start, every word will be assigned a vector with random numbers. \n","\n","A RNN is basically a model that incrementally builds a hidden representation by incorporating one new word at a time. The RNN’s output after reading the final word in part of a sentence is what we’ll use to predict the next word, and this will be a key part of training the model in Step 3. \n","\n","\n"]},{"cell_type":"code","metadata":{"id":"dAazfehEBgT4","colab_type":"code","colab":{}},"source":["# STEP 2.3\n","\n","import torch.nn as nn\n","\n","class EncoderDecoder(nn.Module):\n","  def __init__(self):\n","    \"\"\"\n","        Define all the parameters of the model\n","    \"\"\"\n","    super(EncoderDecoder, self).__init__()\n","    # How tightly should we compress our language represenations?\n","    self.embed_size = 300      # How big is our word vector   #ADVANCED_CHANGEME\n","    self.hidden_size = 600     # How big is our hidden space  #ADVANCED_CHANGEME\n","    \n","    \"\"\" Converting words to Vectors \"\"\"\n","    # A lookup table for translating a word into a vector\n","    self.embedding = nn.Embedding(len(vocabulary), self.embed_size)\n","    # Initialize our word vectors with a random uniform distribution\n","    initrange = 0.1\n","    self.embedding.weight.data.uniform_(-initrange, initrange)\n","\n","    \n","    \"\"\" An RNN (LSTM) with dropout \"\"\"\n","    self.rnn = nn.LSTM(input_size=self.embed_size, hidden_size=self.hidden_size)\n","    self.shrink = nn.Linear(self.hidden_size, self.embed_size)\n","    self.drop = nn.Dropout(p=0.5)\n","    \n","    \"\"\" Predicting words from our model \"\"\"\n","    # We convert our vector to a set of scores over words\n","    self.decode = nn.Linear(self.embed_size, self.embedding.weight.size(0))\n","    # We use the same matrix for this ``decoding'' that we used for ``encoding''\n","    # https://arxiv.org/abs/1608.05859\n","    self.decode.weight = self.embedding.weight\n","    self.decode.bias.data.zero_()\n","   \n","  \n","  def forward(self, input, hidden=None):\n","    \"\"\"\n","        Run the model\n","    \"\"\"\n","    # 1. Map words to vectors\n","    embedded = self.embedding(input)\n","    # 2. Process with an RNN\n","    if hidden is not None:\n","      output, hidden = self.rnn(embedded, hidden)\n","    else:\n","      output, hidden = self.rnn(embedded)\n","    # 3. Apply dropout\n","    output = F.relu(self.shrink(self.drop(output)))\n","    # 4. Score the likelihood of every possible next word\n","    decoded = self.decode(output)\n","    return hidden, decoded"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Mb4y0r7WXibS","colab_type":"text"},"source":["## Step 3: Model Training"]},{"cell_type":"markdown","metadata":{"id":"Ty3HvLO6wO1b","colab_type":"text"},"source":["Now it's time to iterate over our dataset (specifically, those pieces called batches) and run backpropagation on each example to train the model’s weights. Over the span of one epoch of training this model, the network will loop over every batch of data -- reading it in, building representations, predicting the next word, and then updating its guesses. \n","\n","To start, we're going to train our model over 10 epochs, so this might take a couple minutes to run. \n","\n","We’ll print two numbers with each epoch, which are the model’s training and validation perplexities. As the model learns, it realizes there are fewer and fewer good choices for the next word. The perplexity is a measure of how well the model has narrowed down the choices. We can interpret perplexity as the average number of guesses the model makes before it predicts the right answer. "]},{"cell_type":"code","metadata":{"id":"UPA-jER1YPN1","colab_type":"code","colab":{}},"source":["# STEP 3.1\n","\n","import torch.nn.functional as F\n","def training(model, data, targets, lr, hidden):\n","  # Reset the model\n","  model.zero_grad()\n","\n","  # Run the model to see its predictions and hidden states\n","  hidden, prediction_vector = model(data, hidden)\n","  prediction_vector = prediction_vector.view(seq_len * batch_size, -1)\n","\n","  # Compare the model's predictions at each timestep to the original data\n","  loss = F.cross_entropy(prediction_vector, targets)\n","  \n","  # Compute gradients and perform back-propagation\n","  loss.backward()\n","  torch.nn.utils.clip_grad_norm_(model.parameters(), 0.25)\n","  for p in model.parameters():\n","      if p.grad is not None:\n","        p.data.add_(-lr, p.grad.data)\n","  \n","  # Return the current model loss on this data item\n","  return loss.item(), repackage_hidden(hidden)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wEE6G8FhZ_px","colab_type":"code","colab":{}},"source":["# STEP 3.2\n","\n","def evaluation(model):\n","  \"\"\"\n","    This function performs almost all the same logic as the training function\n","    but it does not perform backpropagation, because we don't want to learn\n","    from this data, just check our performance.\n","  \"\"\"\n","  model.eval()\n","  hidden = None\n","  valid_loss = 0\n","  for i in range(0, valid.size(0) - seq_len, seq_len):\n","    data, targets = get_batch(valid, i, seq_len)\n","    hidden, prediction_vector = model(data, hidden) \n","    hidden = repackage_hidden(hidden)\n","\n","    prediction_vector = prediction_vector.view(-1, len(vocabulary))\n","    loss = F.cross_entropy(prediction_vector, targets)\n","    valid_loss += loss.item() \n","  return valid_loss / (valid.size(0)/seq_len)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zUM8SRBgBjBQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":346},"outputId":"6d58c706-7380-45fd-a5e9-52a23f076fa2","executionInfo":{"status":"error","timestamp":1589037861200,"user_tz":-180,"elapsed":16186,"user":{"displayName":"Turhan Can Kargın","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_nBTtpJH69xacdXtHC85zJwK_OgZQ-lAUwUqgYqo=s64","userId":"17271240165502760084"}}},"source":["# STEP 3.3\n","\n","# Create an instance of the model\n","import numpy as np\n","import time\n","model = EncoderDecoder().float().to(device)\n","prev_valid_loss = 1e100\n","# This scales the size of each step of backpropagation\n","learning_rate = 20\n","# This value should match the batch_size used earlier for splitting up the data\n","batch_size = 20\n","\n","num_epochs = 10                # CHANGEME\n","timing = time.time()\n","for epoch in range(num_epochs):\n","\n","  # Set the model to training mode and iterate through the dataset\n","  model.train()\n","  hidden = None\n","  train_loss = 0\n","  start_time = time.time()\n","  for i in range(0, train.size(0) - 1, seq_len):\n","    # Get the next training batch\n","    data, targets = get_batch(train, i, seq_len)\n","    \n","    # Run the model and perform backpropagation\n","    loss, hidden = training(model, data, targets, learning_rate, hidden)\n","    train_loss += loss\n","\n","  # Evaluate how well the model predicts unseen validation data\n","  valid_loss = evaluation(model)\n","\n","  # Check if the model's ability to generalize has gotten worse.\n","  # If so, slow the learning rate (shrink the step size)\n","  if valid_loss > prev_valid_loss:\n","    learning_rate /= 4.0\n","\n","  # Print the training and validation performance\n","  train_loss /= (train.size(0)/seq_len)\n","  finish_time = time.time()\n","  print(\"Epoch {:2} took {:3.2f}s with train perplexity: {:7.2f}\"\\\n","        \" and validation: {:7.2f}\".format(epoch, finish_time - start_time, \n","                                          np.exp(train_loss), \n","                                          np.exp(valid_loss)))\n","  \n","  prev_valid_loss = valid_loss\n","\n","total_time = (time.time() - timing)/60\n","print(\"Completed {} epochs in {:5.3f} minutes\".format(num_epochs, total_time))\n"],"execution_count":17,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-38e614cd772b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# Run the model and perform backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-14-c8c8f8019d86>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(model, data, targets, lr, hidden)\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;31m# Run the model to see its predictions and hidden states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mprediction_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction_vector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_len\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;31m# Compare the model's predictions at each timestep to the original data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: shape '[700, -1]' is invalid for input of size 234300"]}]},{"cell_type":"markdown","metadata":{"id":"0FN3WcghH3E7","colab_type":"text"},"source":["## Step 4: Inference"]},{"cell_type":"markdown","metadata":{"id":"gDZIYD6gczG0","colab_type":"text"},"source":["So far in Crash Course AI, we've looked at models that produce a \"best label\" or \"best prediction,\" but  here, there is no \"right\" answer. We're just building a generative model -- a model that can generate outputs.\n","\n","If we wrote stories by always having characters do the most obvious next thing, they’d be pretty boring. So we’re going to implement a basic sampler in our program, whicih will take a bunch of random paths instead of just choosing the highest-scoring next word every time. \n","\n","We can sort the results by the probability of the full sentences, and we can see which sentences are best overall. \n","\n","To start this generation, we need to give our model a word to begin every sentence. Let’s try “Good” for now, but you can try other things by changing the code. "]},{"cell_type":"code","metadata":{"id":"QkSJrjFhig8l","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":840},"outputId":"4a3f75c4-92fb-4882-e58c-b38bb61e0ac9","executionInfo":{"status":"ok","timestamp":1589037903428,"user_tz":-180,"elapsed":13330,"user":{"displayName":"Turhan Can Kargın","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_nBTtpJH69xacdXtHC85zJwK_OgZQ-lAUwUqgYqo=s64","userId":"17271240165502760084"}}},"source":["# STEP 4.1\n","\n","# What do we want the model to start the sentence with?\n","prefix = \"<s> Good\"      #CHANGEME\n","\n","# How many words do we want the model to produce?  \n","words_to_generate = 50   #CHANGEME\n","\n","# We are only going to be looking at one example at a time\n","batch_size = 1\n","\n","# Set the model to be in evaluation mode (no backprop!)\n","model.eval()\n","\n","# Let's get lots of possible sentences\n","argmax_sent = None\n","argmax_prob = 0\n","collection = []\n","for item in range(100):\n","  # Convert our sentence start into numbers\n","  test = [word_to_num[word] if word in word_to_num else word_to_num[\"unk\"] \\\n","          for word in prefix.split()]\n","  probabilities = []\n","  \n","  # Run the model on the same initial input and it's own generations until\n","  # we reach `word_to_generate`\n","  for w in range(words_to_generate):\n","    # Run the model\n","    input = torch.from_numpy(np.array(test)).to(device)\n","    _, output = model(input.view(-1,1))\n","    \n","    # Get the prediction for the last (next) word\n","    last_pred = output[-1,:,:].squeeze()        \n","    \n","    # We're going to block generation of unk \n","    last_pred[word_to_num[\"unk\"]] = -100   \n","    \n","    # Do we want to sample from this distrubtion?\n","    if item > 0:\n","      # A temperature makes the distribution peakier (if < 1) or flatter if > 1\n","      last_pred /= 0.70   #ADVANCED_CHANGEME\n","\n","      # Turn this into a distribution\n","      dist = torch.distributions.categorical.Categorical(logits=last_pred)\n","      \n","      # Sample\n","      predicted_idx = dist.sample().item()\n","      \n","    else:\n","      # If we aren't sampling, just take the most probable word\n","      _, predicted_idx = last_pred.max(0)\n","      predicted_idx = predicted_idx.item()\n","\n","    # Save the predicted word's probability\n","    value = F.log_softmax(last_pred,-1)[predicted_idx].item()\n","    \n","    # Add this predicted word (index) to the list\n","    test.append(predicted_idx)\n","    # Save the probability for sorting later\n","    probabilities.append(value)\n","    \n","  if item > 0:\n","    # Add our sentence and its score to a list\n","    generation = (np.exp(np.sum(probabilities)), \\\n","                       \" \".join([num_to_word[w] for w in test]))\n","    if generation not in collection:\n","      collection.append(generation)\n","  else:\n","    argmax_sent = \" \".join([num_to_word[w] for w in test])\n","    argmax_prob = np.exp(np.sum(probabilities))\n","\n","# Get the best model predictions\n","collection.sort()\n","collection.reverse()\n","print(\"Argmax Generation:\")\n","print(\"{:.2E}:  {}\\n\".format(argmax_prob,\"\\n\\t\\t\".join(wrap(argmax_sent))))\n","print(\"\\nSampled Generations:\")\n","for probability, sent in collection[:10]:\n","  print(\"{:.2E}:  {}\\n\".format(probability, \"\\n\\t\\t\".join(wrap(sent))))"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Argmax Generation:\n","2.13E-32:  <s> Good morn ing Hank , it 's Tuesday . I 'm go ing to be a good  and\n","\t\tI 'm go ing to be a good  and I 'm go ing to be a good  and I 'm go\n","\t\ting to be a good  and I 'm\n","\n","\n","Sampled Generations:\n","1.91E-13:  <s> Good morn ing Hank , it 's Tuesday . </s> <s> Good morn ing Hank ,\n","\t\tit is Tuesday . Hank , I 'll see you on Friday . </s> <s> Good morn\n","\t\ting Hank , it 's Tuesday . And then I 'm go ing to make you . Not\n","\n","4.39E-18:  <s> Good morn ing Hank , it 's Tuesday . Hank , I 'm go ing to be a\n","\t\tquestion , you 'll see you on Friday . </s> <s> Good morn ing Hank ,\n","\t\tit 's Tuesday . It is like a book of the world in the Unit ed States\n","\n","6.68E-19:  <s> Good morn ing Hank , it is it . </s> <s> Good morn ing Hank , it\n","\t\t's Tuesday . </s> <s> Good morn ing Hank , it 's Tuesday . It is why\n","\t\tyou 're wonder ing to me . You 'll see you on Friday . </s> <s> Good\n","\n","1.51E-19:  <s> Good morn ing Hank , it 's Thursday . \" Hank , I 'll see you on\n","\t\tFriday . </s> <s> Good morn ing Hank , it 's Tuesday . Then I just see\n","\t\tyou on Friday . </s> <s> Good morn ing Hank , it 's Monday . Uh ,\n","\n","9.76E-22:  <s> Good morn ing Hank , it 's Tuesday . I 'm gett ing free . Hank , I\n","\t\t'll see you on Friday . </s> <s> Good morn ing Hank , it 's Tuesday .\n","\t\tAnd I do n't just like to go to be a lot of the \" \"\n","\n","2.06E-23:  <s> Good morn ing Hank , it 's Tuesday . OK , I 'm go ing to get a\n","\t\tminimum economy . Hank , I 'm go ing to raise you on Monday . </s> <s>\n","\t\tGood morn ing Hank , it 's Tuesday . I 'll see you on Friday .\n","\n","1.17E-23:  <s> Good morn ing Hank , it 's Tuesday . I 'll see you on Friday .\n","\t\t</s> <s> Good morn ing Hank , it 's Tuesday . I 'll see you tomorrow .\n","\t\t</s> <s> Good morn ing Hank , it is the girl of like you matt er would\n","\t\tbe\n","\n","5.16E-25:  <s> Good morn ing Hank , it is this story of the numb er of the real\n","\t\tly  I do n't know to be a hotel  and I 'll see you on Friday . </s>\n","\t\t<s> Good morn ing Hank , it 's Tuesday . \" What is more than\n","\n","3.88E-26:  <s> Good morn ing Hank , it 's Tuesday . </s> <s> Good morn ing Hank ,\n","\t\tit is Tuesday . </s> <s> Good morn ing Hank , it 's Tuesday . Also , I\n","\t\thave a great little bit for the world . I 'm a new story of this new\n","\n","1.47E-26:  <s> Good morn ing Hank , it 's Tuesday . Like , you 'll see you\n","\t\ttomorrow . </s> <s> Good morn ing Hank , it 's Tuesday . Let is like\n","\t\tto be a bad and I do n't think that I will think that I would be a\n","\t\tlink to\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AiABIZxixgcb","colab_type":"text"},"source":["The sentence we get from taking the highest probability word each time (the Argmax) isn’t as interesting as the ones where we mixed it up a bit and took different branches (the other Sampled Generations). \n","\n","Building models that interact with people, and the world, is why natural language processing is so exciting, but it’ll take a lot more work to get our model to generate language as well as human John Green does.\n","\n","We’ve left a bunch of notes in the code for you to play with when making your own AI! You could train for longer, change the sentence prompt, or, if you’re feeling adventurous, replace the text data to speak in someone else’s voice. All you need is transcripts of their videos to get started.\n"]}]}